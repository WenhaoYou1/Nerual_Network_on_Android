% 1. Abstract 首次出现 - 1
@article{zhao2023frequency, 
	title={Frequency Regularization: Reducing Information Redundancy in Convolutional Neural Networks},
	author={Zhao, C. and Dong, G. and Zhang, S. and Tan, Z. and Basu, A.},
	journal={IEEE Access},
	year={2023},
	volume={},
	number={},
	pages={},
	note={Department of Computing Science, University of Alberta, Edmonton, AB},
	doi={10.1109/ACCESS.2023.3320642},
	month={September},
	received={12 September 2023},
	accepted={25 September 2023},
	publication_date={28 September 2023},
	current_version_date={4 October 2023}
}

% 1. Abstract 首次出现 - 2
@InProceedings{akusok2019metal,
	author="Akusok, Anton
	and Leal, Leonardo Espinosa
	and Bj{\"o}rk, Kaj-Mikael
	and Lendasse, Amaury",
	editor="Cao, Jiuwen
	and Vong, Chi Man
	and Miche, Yoan
	and Lendasse, Amaury",
	title="High-Performance ELM for Memory Constrained Edge Computing Devices with Metal Performance Shaders",
	booktitle="Proceedings of ELM2019",
	year="2021",
	publisher="Springer International Publishing",
	address="Cham",
	pages="79--88",
	abstract="This paper proposes a block solution method for the Extreme Learning Machine. It combines the speed of a direct non-iterative solver with minimal memory requirements. The method is suitable for edge computing scenarios running on a mobile device with GPU acceleration. The implementation tested on the GPU of iPad Pro outperforms a laptop CPU, and trains a 19,000-neuron model using under one gigabyte of memory. It confirms the feasibility of Big Data analysis on modern mobile devices.",
	isbn="978-3-030-58989-9"
}

% 1. Abstract 首次出现 - 3
@inproceedings{fang2018nestdnn,
	author = {Fang, Biyi and Zeng, Xiao and Zhang, Mi},
	year = {2018},
	month = {10},
	pages = {115-127},
	title = {NestDNN: Resource-Aware Multi-Tenant On-Device Deep Learning for Continuous Mobile Vision},
	doi = {10.1145/3241539.3241559}
}
% 1. Abstract 首次出现 - 4
@article{kim2016compression,
	author = {Kim, Yong-Deok and Park, Eunhyeok and Yoo, Sungjoo and Choi, Taelim and Yang, Lu and Shin, Dongjun},
	year = {2015},
	month = {11},
	pages = {},
	title = {Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications}
}

% 2. Introduction 首次出现 - 5
@article{wang2018privacy,
	author = {Wang, Ji and Zhang, Jianguo and Bao, Weidong and Zhu, Xiaomin and Cao, Bokai and Yu, Philip},
	year = {2018},
	month = {09},
	pages = {},
	title = {Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud}
}

% 3.1 Upgrade Hardware 首次出现 - 6
@InProceedings{Andrey2019Aibenchmark,
	author="Ignatov, Andrey
	and Timofte, Radu
	and Chou, William
	and Wang, Ke
	and Wu, Max
	and Hartley, Tim
	and Van Gool, Luc",
	editor="Leal-Taix{\'e}, Laura
	and Roth, Stefan",
	title="AI Benchmark: Running Deep Neural Networks on Android Smartphones",
	booktitle="Computer Vision -- ECCV 2018 Workshops",
	year="2019",
	publisher="Springer International Publishing",
	address="Cham",
	pages="288--314",
	abstract="Over the last years, the computational power of mobile devices such as smartphones and tablets has grown dramatically, reaching the level of desktop computers available not long ago. While standard smartphone apps are no longer a problem for them, there is still a group of tasks that can easily challenge even high-end devices, namely running artificial intelligence algorithms. In this paper, we present a study of the current state of deep learning in the Android ecosystem and describe available frameworks, programming models and the limitations of running AI on smartphones. We give an overview of the hardware acceleration resources available on four main mobile chipset platforms: Qualcomm, HiSilicon, MediaTek and Samsung. Additionally, we present the real-world performance results of different mobile SoCs collected with AI Benchmark (http://ai-benchmark.com) that are covering all main existing hardware configurations.",
	isbn="978-3-030-11021-5"
}
% 5. Timeline 首次出现 - 7
@website{pytorch_mobile,
	title = {PyTorch Mobile: End-to-end workflow from Training to Deployment for iOS and Android mobile devices},
	publisher = {The Linux Foundation},
	year = {2023}, 
	note = {Accessed: 2023-10-15}, % 您在2023年10月15日访问了该网站
	url = {https://pytorch.org/mobile/home/}
}

% 7.1 首次出现 - 8
@misc{utmel2020dsp, 
	title={An overview of digital signal processor}, url={https://www.utmel.com/blog/categories/microprocessors/an-overview-of-digital-signal-processor}, 
	journal={An Overview of Digital Signal Processor}, 
	publisher={Utmel Electronics}, 
	author={Utmel}, 
	year={2020}, 
	month={Jul}
} 

% 7.2 首次出现 - 9
@Inbook{picton1994neural,
	author="Picton, Phil",
	title="What is a Neural Network?",
	bookTitle="Introduction to Neural Networks",
	year="1994",
	publisher="Macmillan Education UK",
	address="London",
	pages="1--12",
	abstract="This is the first question that everybody asks. It can be answered more easily if the question is broken down into two parts.",
	isbn="978-1-349-13530-1",
	doi="10.1007/978-1-349-13530-1_1",
	url="https://doi.org/10.1007/978-1-349-13530-1_1"
}

% 首次出现 - 10
@misc{neill2020overview,
	title={An Overview of Neural Network Compression}, 
	author={James O' Neill},
	year={2020},
	eprint={2006.03669},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@InProceedings{jin2014implement,
	author="Jin, Jonghoon and Gokhale, Vinayak and Dundar, Aysegul and Krishnamurthy, Bharadwaj and Martini, Berin and Culurciello, Eugenio",
	booktitle="2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS)", 
	title="An efficient implementation of deep convolutional neural networks on a mobile coprocessor", 
	year="2014",
	volume="",
	number="",
	pages="133-136",
	doi="10.1109/MWSCAS.2014.6908370"}


@INPROCEEDINGS{cast2020integration,
	author={Castanyer, Roger Creus and Martínez-Fernández, Silverio and Franch, Xavier},
	booktitle={2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)}, 
	title={Integration of Convolutional Neural Networks in Mobile Applications}, 
	year={2021},
	volume={},
	number={},
	pages={27-34},
	doi={10.1109/WAIN52551.2021.00010}}
	
@inproceedings{NEURIPS2018,
	author = {Liu, Zhenhua and Xu, Jizheng and Peng, Xiulian and Xiong, Ruiqin},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Frequency-Domain Dynamic Pruning for Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/a9a6653e48976138166de32772b1bf40-Paper.pdf},
	volume = {31},
	year = {2018}
}


@ARTICLE{cao2020edgecomputing,
	author={Cao, Keyan and Liu, Yefan and Meng, Gongjie and Sun, Qimeng},
	journal={IEEE Access}, 
	title={An Overview on Edge Computing Research}, 
	year={2020},
	volume={8},
	number={},
	pages={85714-85728},
	doi={10.1109/ACCESS.2020.2991734}}

% 三篇paper对应 四种compression的tech
@misc{cheng2020survey,
	title={A Survey of Model Compression and Acceleration for Deep Neural Networks}, 
	author={Yu Cheng and Duo Wang and Pan Zhou and Tao Zhang},
	year={2020},
	eprint={1710.09282},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{pal2020autoencoding,
	title={Auto-Encoding for Shared Cross Domain Feature Representation and Image-to-Image Translation}, 
	author={Safalya Pal},
	year={2020},
	eprint={2006.11404},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{gol2021control,
	title={Control Synthesis for Parametric Timed Automata under Unavoidability Specifications}, 
	author={Ebru Aydin Gol},
	year={2021},
	eprint={2104.09154},
	archivePrefix={arXiv},
	primaryClass={cs.FL}
}


