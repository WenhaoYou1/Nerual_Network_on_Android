\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{zhao2023frequency}
\citation{akusok2019metal}
\citation{fang2018nestdnn}
\citation{kim2016compression}
\citation{wang2018privacy}
\citation{wang2018privacy}
\citation{zhao2023frequency}
\citation{zhao2023frequency}
\citation{zhao2023frequency}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{1}{section.2}\protected@file@percent }
\citation{zhao2023frequency}
\citation{akusok2019metal}
\citation{fang2018nestdnn}
\citation{kim2016compression}
\citation{akusok2019metal}
\citation{Andrey2019Aibenchmark}
\citation{akusok2019metal}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the proposed frequency regularization. The tail elements of tensors in the frequency domain are truncated first, then input into the inverse of the discrete cosine transform to reconstruct the spatial tensor for learning features\nobreakspace  {}\cite  {zhao2023frequency}.}}{2}{figure.1}\protected@file@percent }
\newlabel{idct}{{1}{2}{Illustration of the proposed frequency regularization. The tail elements of tensors in the frequency domain are truncated first, then input into the inverse of the discrete cosine transform to reconstruct the spatial tensor for learning features~\cite {zhao2023frequency}}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Brief Summary of Existing Work}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Upgrade Hardware}{2}{subsection.3.1}\protected@file@percent }
\newlabel{upgrade_hardware}{{3.1}{2}{Upgrade Hardware}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Algorithm Extreme Learning Machine (ELM)}{2}{subsection.3.2}\protected@file@percent }
\newlabel{elm}{{3.2}{2}{Algorithm Extreme Learning Machine (ELM)}{subsection.3.2}{}}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{kim2016compression}
\citation{zhao2023frequency}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Algorithm NestDNN}{3}{subsection.3.3}\protected@file@percent }
\newlabel{nestdnn}{{3.3}{3}{Algorithm NestDNN}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces NestDNN architecture\nobreakspace  {}\cite  {fang2018nestdnn}.}}{3}{figure.2}\protected@file@percent }
\newlabel{nestdnn_arch}{{2}{3}{NestDNN architecture~\cite {fang2018nestdnn}}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Five terminologies involved in NestDNN.}}{3}{table.1}\protected@file@percent }
\newlabel{nest-table}{{1}{3}{Five terminologies involved in NestDNN}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Algorithm One-shot Whole Network Compression}{3}{subsection.3.4}\protected@file@percent }
\newlabel{oneshot}{{3.4}{3}{Algorithm One-shot Whole Network Compression}{subsection.3.4}{}}
\citation{zhao2023frequency}
\citation{pytorch_mobile}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Algorithm Frequency Regularization}{4}{subsection.3.5}\protected@file@percent }
\newlabel{fr}{{3.5}{4}{Algorithm Frequency Regularization}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}What you Plan To Do}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}How You Plan to Implement Your Ideas (Timeline)}{4}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Timeline for FR implementation on Mobile Devices}}{4}{figure.3}\protected@file@percent }
\newlabel{timeline_fig}{{3}{4}{Timeline for FR implementation on Mobile Devices}{figure.3}{}}
\citation{Andrey2019Aibenchmark}
\citation{utmel2020dsp}
\citation{utmel2020dsp}
\citation{utmel2020dsp}
\citation{utmel2020dsp}
\citation{Andrey2019Aibenchmark}
\@writefile{toc}{\contentsline {section}{\numberline {6}Short Description of 5 LABS (Milestones)}{5}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Literature Review}{5}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Review of AI Benchmark for Running Deep Neural Networks}{5}{subsection.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Digital signal processor (DSP)\nobreakspace  {}\cite  {utmel2020dsp}.}}{5}{figure.4}\protected@file@percent }
\newlabel{dsp-image}{{4}{5}{Digital signal processor (DSP)~\cite {utmel2020dsp}}{figure.4}{}}
\citation{akusok2019metal}
\citation{fang2018nestdnn}
\citation{kim2016compression}
\citation{zhao2023frequency}
\citation{picton1994neural}
\citation{neill2020overview}
\citation{han2015learning}
\citation{han2016deep}
\citation{liu2019improving}
\citation{ye2018learning}
\citation{han2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces DSP internal structure\nobreakspace  {}\cite  {utmel2020dsp}.}}{6}{figure.5}\protected@file@percent }
\newlabel{dsp-structure}{{5}{6}{DSP internal structure~\cite {utmel2020dsp}}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Review of Neural Network}{6}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Review of Compression of Neural Network}{6}{subsection.7.3}\protected@file@percent }
\citation{han2016deep}
\citation{liu2019improving}
\citation{ye2018learning}
\citation{akusok2019metal}
\citation{erdem2020elmimage}
\citation{cao2020edgecomputing}
\citation{akusok2019metal}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Review of High-Performance Extreme Learning Machine (ELM)}{7}{subsection.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A simple illustration on how ELM process works\nobreakspace  {}\cite  {erdem2020elmimage}.}}{7}{figure.6}\protected@file@percent }
\newlabel{elm-layers-image}{{6}{7}{A simple illustration on how ELM process works~\cite {erdem2020elmimage}}{figure.6}{}}
\citation{akusok2019metal}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\citation{fang2018nestdnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Review of NestDNN}{8}{subsection.7.5}\protected@file@percent }
\citation{fang2018nestdnn}
\citation{kim2016compression}
\citation{kim2016compression}
\citation{kim2016compression}
\citation{kim2016compression}
\citation{kim2016compression}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Review of One-shot Whole Network Compression}{9}{subsection.7.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The scheme of one-show whole network compression, which includes three steps\nobreakspace  {}\cite  {kim2016compression}.}}{9}{figure.7}\protected@file@percent }
\newlabel{one-shot-steps}{{7}{9}{The scheme of one-show whole network compression, which includes three steps~\cite {kim2016compression}}{figure.7}{}}
\citation{zhao2023frequency}
\citation{zhao2023frequency}
\citation{NEURIPS2018}
\citation{zhao2023frequency}
\citation{zhao2023frequency}
\citation{zhao2023frequency}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Review of Frequency Regularization}{10}{subsection.7.7}\protected@file@percent }
\citation{jin2014implement}
\citation{jin2014implement}
\citation{cast2020integration}
\bibstyle{unsrt}
\bibdata{ref.bib}
\bibcite{zhao2023frequency}{1}
\bibcite{akusok2019metal}{2}
\bibcite{fang2018nestdnn}{3}
\bibcite{kim2016compression}{4}
\bibcite{wang2018privacy}{5}
\bibcite{Andrey2019Aibenchmark}{6}
\bibcite{pytorch_mobile}{7}
\bibcite{utmel2020dsp}{8}
\bibcite{picton1994neural}{9}
\bibcite{neill2020overview}{10}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8}Review on Implementation on Mobile Devices}{11}{subsection.7.8}\protected@file@percent }
\bibcite{han2015learning}{11}
\bibcite{han2016deep}{12}
\bibcite{liu2019improving}{13}
\bibcite{ye2018learning}{14}
\bibcite{erdem2020elmimage}{15}
\bibcite{cao2020edgecomputing}{16}
\bibcite{NEURIPS2018}{17}
\bibcite{jin2014implement}{18}
\bibcite{cast2020integration}{19}
\gdef \@abspage@last{12}
